name: Node.js CICD

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  compile:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '23'

      - name: Frontend Compilation (Syntax Check)
        run: |
          cd client
          find . -name "*.js" -exec node --check {} +
      - name: Backend Compilation (Syntax Check)
        run: |
          cd api
          find . -name "*.js" -exec node --check {} +

  gitleaks-scan:
    runs-on: ubuntu-latest
    needs: compile
    steps:
      - uses: actions/checkout@v4
      - uses: gitleaks/gitleaks-action@v2
      - name: Gitleaks Scan
        run: |
          gitleaks detect --source ./client --exit-code 1
          gitleaks detect --source ./api --exit-code 1

  trivy_fs_scan:
    runs-on: ubuntu-latest
    needs: gitleaks-scan
    steps:
      - uses: actions/checkout@v4
      - uses: aquasecurity/trivy-action@0.28.0
        with:
          scan-type: fs
          scan-ref: '.'
          format: table
          ignore-unfixed: true
          vuln-type: os,library
          severity: CRITICAL,HIGH

  sonar-frontend:
    runs-on: ubuntu-latest
    needs: trivy_fs_scan
    steps:
      - uses: actions/checkout@v4
      - uses: actions/cache@v4
        with:
          path: ~/.sonar/cache
          key: ${{ runner.os }}-sonar
      - uses: sonarsource/sonarqube-scan-action@master
        with:
          projectBaseDir: client
          args: >
            -Dsonar.projectKey=myorg_client
            -Dsonar.projectName=myorg_client
            -Dsonar.sources=.
            -Dsonar.exclusions=**/node_modules/**,**/dist/**,**/build/**
        env:
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
          SONAR_HOST_URL: ${{ secrets.SONAR_HOST_URL }}

  sonar-backend:
    runs-on: ubuntu-latest
    needs: sonar-frontend
    steps:
      - uses: actions/checkout@v4
      - uses: actions/cache@v4
        with:
          path: ~/.sonar/cache
          key: ${{ runner.os }}-sonar
      - uses: sonarsource/sonarqube-scan-action@master
        with:
          projectBaseDir: api
          args: >
            -Dsonar.projectKey=myorg_api
            -Dsonar.projectName=myorg_api
            -Dsonar.sources=.
            -Dsonar.exclusions=**/node_modules/**,**/dist/**,**/build/**
        env:
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
          SONAR_HOST_URL: ${{ secrets.SONAR_HOST_URL }}

  build_backend_docker_image_and_push:
    runs-on: ubuntu-latest
    needs: sonar-backend
    steps:
      - uses: actions/checkout@v4
      - uses: docker/login-action@v3
        with:
          username: ${{ vars.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_TOKEN }}
      - uses: docker/setup-qemu-action@v3
      - uses: docker/setup-buildx-action@v3
      - uses: docker/build-push-action@v6
        with:
          context: ./api
          push: true
          tags: eshu786/backend:latest
          file: ./api/Dockerfile

  build_frontend_docker_image_and_push:
    runs-on: ubuntu-latest
    needs: sonar-backend
    steps:
      - uses: actions/checkout@v4
      - uses: docker/login-action@v3
        with:
          username: ${{ vars.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_TOKEN }}
      - uses: docker/setup-qemu-action@v3
      - uses: docker/setup-buildx-action@v3
      - uses: docker/build-push-action@v6
        with:
          context: ./client
          push: true
          tags: eshu786/frontend:latest
          file: ./client/Dockerfile

  trivy_image_scan:
    runs-on: ubuntu-latest
    needs: build_frontend_docker_image_and_push
    steps:
      - uses: actions/checkout@v4
      - uses: aquasecurity/trivy-action@0.28.0
        with:
          scan-type: image
          image-ref: eshu786/backend:latest
          format: table
          exit-code: '0'
          ignore-unfixed: true
          vuln-type: os,library
          severity: CRITICAL,HIGH
      - uses: aquasecurity/trivy-action@0.28.0
        with:
          scan-type: image
          image-ref: eshu786/frontend:latest
          format: table
          exit-code: '0'
          ignore-unfixed: true
          vuln-type: os,library
          severity: CRITICAL,HIGH

  deploy_to_kubernetes:
    runs-on: ubuntu-latest
    needs: trivy_image_scan
    steps:
      - uses: actions/checkout@v4
      - name: Install AWS CLI
        run: |
          curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
          unzip awscliv2.zip
          sudo ./aws/install --update
      - uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ap-south-1
      - uses: azure/setup-kubectl@v3
        with:
          version: latest
      - name: Configure kubeconfig
        run: |
          mkdir -p $HOME/.kube
          echo "${{ secrets.EKS_KUBECONFIG }}" | base64 -d > $HOME/.kube/config

      - name: Install ingress-nginx if not present
        run: |
          if ! kubectl get ns prod -o jsonpath='{.metadata.name}' >/dev/null 2>&1; then
            kubectl create ns prod
          fi
          if ! kubectl get svc -n prod ingress-nginx-controller >/dev/null 2>&1; then
            kubectl apply -n prod -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/main/deploy/static/provider/cloud/deploy.yaml
            echo "Waiting for ingress-nginx-controller external IP..."
            kubectl wait --namespace prod --for=condition=ready pod -l app.kubernetes.io/component=controller --timeout=600s
          fi

      - name: Deploy Kubernetes resources
        run: |
          kubectl apply -f k8s-prod/sc.yaml
          kubectl apply -f k8s-prod/mysql.yaml
          kubectl apply -f k8s-prod/backend.yaml
          kubectl apply -f k8s-prod/frontend.yaml
          kubectl apply -f k8s-prod/ci.yaml

      - name: Deploy Ingress with nip.io + TLS
        run: |
          ELB_HOSTNAME=$(kubectl get svc -n prod ingress-nginx-controller -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')
          echo "Using ELB hostname: $ELB_HOSTNAME"
          sed "s|<ELB_HOSTNAME>|$ELB_HOSTNAME|g" k8s-prod/ingress.yaml | kubectl apply -f -
